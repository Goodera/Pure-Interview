云帆加速面试总结
这家公司是提供直播视频加速的，对实时处理要求高点，部分hadoop知识，还有对storm和es，kafka也有要求

首先是简单做自我介绍，然后问三年在一家公司进去就做大数据嘛？

然后大致的问啦一下说最近的项目，简单介绍一下！
我说的是最近的一个数仓，把实现流程简单描述啦下。

然后问有没有遇到过什么问题，在数仓项目中！
我说：
1）Sqoop导数据有blob字段，导致导入出现缓存不够的情况，后面查看sqoop文档给它加啦limit属性(设定大对象数据的最大值)
2）在导到hive时会出现报错，因为blob字段会导致出现空值，vi oraoop-site.xml更改配置信息，去点注释，将blob字段禁用，采用指定的字段去导入。
3）导数据的时候因为默认分割符的原因，默认列分隔符是“\001”，默认行分割符是“\n”，导入时出现行分割符会将后面的数据当成另一条数据；
加上参数Chive-drop-import-delims来把导入数据中包含的hive默认的分隔符去掉

你做数仓写指标为什么不直接就用数据库里面的数据进行join来操作，就是为什么要有这些ods层，dm层
我说：
数仓的数据是有历史意义的，面像主题的，而且数据量会越来越大，需要单独将数据拿出来做针对主题的分析，而且这些面向具体主题的数据一般不会去改动，
海量的分析数据也不适合直接放到数据库。他公司也没做过数仓也没说什么！


hive里面有没有哪些优化？
1，大小表join时小表放置前边！原因：需要选择哪个表被流式传输（stream），哪个表被缓存！
2，Mapjoin将小表放入内存，在map端和大表逐一匹配，从而省去reduce
3，当数据量比较大的时候常用的手段就是为拆分表，大表拆小表，分区表 ，临时表 。
4，外部表小表和大表join  ,要把数据量的小的表放在join的左边，先进行缓存 ,这样减少表Join的时候内存的消耗量
5，set hive.exec.parallel=true  ; // 开启任务并行执行
6，set hive.exec.parallel.thread.number=8; //默认值为8个任务可以同时运行
7，开启严格模式，为了防止一些查询。出现不好的影响。例如笛卡儿积。
***对于分区表： 必须存在where语句对分区表中分区字段进行条件过滤
***对于使用order by的语句必须使用limit 进行限定
8,JVM重用，避免JVM频繁开启和关闭会造成大量资源浪费
9，推测执行（这个也可以用在mapreduce中）推测执行的条件，使用限制以及原理也可以说一下
10，虚拟列：虚拟列本身是一个不存在列，在数据查询的时候，可以通过虚拟列去查询数据的的路径，以及数据的偏移量

大概都说啦，还具体问啦如何开启并行执行，如何设置同时执行的任务！就是上面这些参数的设置。

还问如果是大表join大表怎么办？当时还有点懵啦，大表之间的join肯定是对性能要求特别高，我就说真正的hive优化还是需要根据业务和具体的实现场景来的，用left join
去替代not exist这样的操作

然后他看我说啦，小表join大表，小表放前面，问完为什么，然后反问，现在left join和right join是不是也一定将小表放前面？
当时还楞啦，因为第一次面试嘛，可以始终把小表放前面，我就不放大表放前面，他的意思就是有那种我需要关键字从大表获取，
用left join的话，在需求上肯定要将大表放前面，那我就死扣我小表就放前面，反正就放前面，那我改用right join，不用left join，不管什么join就放小表
在前。当时有这个意思，但是还是有点小语塞，也没深问啦。


数据倾斜和优化问的特别多，而且不一定认可以上说的这些，需要深入研究下！！！！！！


flume你们公司采集数据的方式？
我说用的是级联的方式，用多个flume采集，对接到一个flume，然后这个flume对接kafka。

然后一直问我那个对接的flume挂啦怎么办？
我说多个flume的 级联方式也是为啦容灾，为啦防止负载均衡，flume本身安全性特别高啦，基于事务的方式，还是管道传输，失败可以溯源，然后开始还介绍啦flume的具体
采集数据的流程，我说如果数据丢啦可以将数据写入文件，用文件进行恢复，然后防止非首个agent宕机，建立集群和主备。
然后死扣说现在我这个flume没啦，采集不了数据啦怎么办，我说啦HA，有个HA机制，说就用两个flume，一个随时待命，如果节点出问题啦，我用另外一个flume，
如果要恢复节点上的数据，就可以将数据写入文件，用文件进行恢复，代理的节点奔溃啦，需要对磁盘进行一个恢复。


个人感觉，会就要答得自信，人家并不是特别懂，说的节奏要把控好，不要语塞，说的合理都可以，要让人觉的真正做过。说话的节奏和方式很重要。

有没有用spark对hive进行处理，就是spark on hive。
我直接说用过，通过改写spark里面的配置文件hive-site-xml，然后对接hive，还要在hive里面的bin下启动metastore

然后问啦reducebykey和groupbykey的区别
我说groupbykey是将相同key对应的value进行一个聚合，会有shuffle，，数据量大会报错，但是reducebykey会提前有个类似于聚合的操作，在性能
上进行啦优化，减少啦传输，保障啦reduce的计算更高效。

kafka和spark streaming的连接方式，好处和弊端，以及问题。
receiver和directer方式，大概表达拉下，在数据receiver在接受数据过程中crash时，需要默认复制spark executors，需要提供可靠的sources和receivers，还有需要checkpoint metadata到HDFS，
就是防止driver失败时，executor会被kill掉导致数据丢失，还有需要开启wal，防止底层数据丢失而丢失，这三个是为了保障数据完整性才需要执行的操作，但那时direct是去指定主题的指定分区去消费，失败可以重新消费，不需要wal；
性能上就更高效。

hive用过哪些函数？
大概说啦下，max（），avg（），sum（），row number over 然后说拉下对用户进行分区，对数据量进行排序，取值。datediff，在统计30天内的数据时就用到这个，还有rank等。

kafka怎么防止数据丢失？
produce端ack，cousmer端的手动offset，副本机制，关闭选举机制等。深入描述下就可以啦。

然后问zookeeper的分布式锁
1.根据指定的路径, 查找zookeeper集群下的这个节点是否存在.(说明已经有锁了)
2. 如果存在, 根据查询者的一些特征数据(如ip地址/hostname), 当前的锁是不是查询者的
3. 如果不是查询者的锁, 则返回null, 说明创建锁失败
4. 如果是查询者的锁, 则把这个锁返回给查询者
5. 如果这个节点不存在, 说明当前没有锁, 那么创建一个临时节点, 并将查询者的特征信息写入这个节点的数据中, 然后返回这个锁.
这算是标准答案，但是我也这样答啦，但是不是这么细，事前是有准备，但是缺乏面试经验，脑子有时候有点 懵，


介绍下kafka的架构？
1 基于Producer-Consumer的Push-Pull使得kafka从数据的主产和消费中方解放出来，专注于数据的吞吐量和传输的速度
2 使用Zookeeper这个业界公认的同步数据框架来管理元数据，使得kafka集群健壮而高效
3 Topics-Partions的组织方式，使得数据可以根据业务进行分类且能够分布式的可靠的存储在不同机器上
4 采用基于内核的sendFile机制进行zero Copy的高效数据传输
5 对于数据的操作采用NIO高效的Channel机制
6 磁盘的顺序读写机制极大的加速啦速度的读写，且不影响并发操作
7 持久化：默认存储数据七天，可以自行更改更长时间 消息系统+存储
8 数据传输过程时，端到端的批量压缩功能，传给kafka集群时依旧保持压缩状态，在Coumser端才进行解压，一般采用GZIP和Snappy进行压缩和解压
9 无状态性：使用zookeeper进行管理元数据时，kafka本身不进行管理元素据和状态，对于Comsumer而言，是Consumer自己去管理元数据
有准备，基本就是这么说的。

kafka和sparkstreaming的数据堆积问题。
我说可以调节消费的时间间隔，然后可以调整批处理的task的量，最后还扯到调节saprk并行度，给资源增加exector，让cpu core变多，在资源的范围内加快消费速度。
还顺便说啦下在spark上下文的一些调优，就是spark调优里面的，他也不是特别懂。

然后还问啦数据倾斜的问题，
本生数据的原因，如果在某几个商品打折，那么此时就可能销售比较多，在进行商品字段整合的时候，求总销售的量，先对这些销售多的某几个先处理count，再和其它字段进行整合。
程序上：可以先group，再count；
参数上：hive.groupby.skewindata=true;发生数据倾斜时会进行负载均衡生成两个job
人家不是很认可，这个是重点的重点，多多准备。要做到理论和代码层都有优化。

然后问啦storm的框架，还有一些storm为什么可以达到实时的效果，以及里面的一些原理。
框架就是照学的说的，然后里面具体的原理没答上来，准备不是特别充分，时间花在项目上啦。

问啦es。
我答啦es的概念是一个分布式快速检索的框架，然后里面有index，type，document，field，mapping然后说啦相应的理解概念，
还有引申拉下查询和 闹裂的知识，后面追问为什么es能做到快速查询检索，我没答上来。

也问啦kylin。
我也是大致描述啦下，说kylin是一个能实现亚秒查询的一个框架，但是它本身的一个原理是用空间换取时间，然后不适合处理特别海量的数据，
会出现问题，它在查询之前是将所有情况都经行过计算的。但是里面具体的操作肯定都不太熟啦，就委婉表达下说了解，但是操作不是特别多，人家也接受，但是有准备是最好的。

大概想起的就这么多，难是不难感觉大家都会，但是这是一家自研的公司，很看重spark和storm，es。
问的人也不是特别专业，很多书面知识他也不一定很清楚，主要还是要做好准备，不能慌，说话节奏和语气要掌控好，
对于处理数据倾斜，负载均衡，shuffle调优这些要特别做准备，我回答的时候没把控好节奏，有点小迷糊，刚面可能是这个样子，最后也聊啦
很多别的东西，关于公司很多情况，可能还要做筛选比对，这家公司大数据岗位的薪资是15到25k，但是问题不难，可能面试人多，大家可以去试试，重点复习下，是个好机会。

没什么特别大收获，就是要有自己的说话方式和节奏，最好能适当延伸扩展。切记不能慌，他根本不在乎你的底细感觉，就是纯粹的面试，顾虑不要太多。重点就是：他很大可能不查学历，看你们的啦。
我说话有点急啦，有点影响到心态啦。还有写的专业技能基本都会提一提！





