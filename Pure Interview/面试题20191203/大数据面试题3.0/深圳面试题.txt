周一：
vivo：
1.hbase建表的原则
2.kafka怎么保证数据消费一次且仅消费一次
3.hive优化（结合hdfs存储）
4.历史数据怎么处理
5.redis数据类型
6.flume有用过吗
7.hbase里的hlog的作用、
8.kafka保证数据一致性和完整性
9.项目中遇到的技术难题
可能大公司都会问一些底层原理，然后项目中遇到的难题
其他问题记不住，两个人面我，他问一个他问一个的
面试之前还有点击紧张，看到两个面试官不紧张了，虽然
技术还可以，但是没气场，就和他们聊。很多原理性东西
回答的不好，所以技术面之后就结束了

超盟金服：
小公司，基本没问什么技术性问题，主要就是聊项目，互相聊看法
1.mr的shuffle
2.sparkRDD的算子
聊完就等人力过来，但是人力过来的有点慢，我们俩又开始聊想法，聊公司大数据相关的
然后人力聊（主要背景和薪资，我说的23k）
没坐上地铁就给我说，给我23k能否接受，我说可以，她问我
确定能来吗？答曰：很看好贵公司，那个总监面试官我也很喜欢他的管理方式，但是现在还
不能100%确定，然后晚上就给邮件offer

周二：
跨越速运：
1.hive抽取第2-10个数据（开窗函数）
2.hive断点续传
3.怎么把一条数据拆分为两条
4.Hbase热点问题
5.Hbase二级排序
公司在城市的物流中心，很偏，吗，满满的乡土气息
又是两个没气场，技术一般的小伙子来面试我
我们聊完一些技术，就开就某些问题进行讨论（因为聊了一会，感觉我应该往一些方向去引导了，就根据他们的
一些问题进行一个深入探讨和争论，因为感受到他们技术一般）
然后人力，聊要了25k，说等通知，两天内给回复

随手科技：
技术大牛来面试，问的很深，很会问，然后就很多不会的，聊完就结束了，公司还不错
一般大数据部门怎么样，就看面试你的技术人员，技术怎么样就行了
1.Hbase组件及其作用
1.Client
包含访问HBase的接口，并维护cache来加快对HBase的访问，比如region的位置信息
2.Master
为Region server分配region
负责Region server的负载均衡
发现失效的Region server并重新分配其上的region
管理用户对table的增删改查操作
3.Region Server
Regionserver维护region，处理对这些region的IO请求
Regionserver负责切分在运行过程中变得过大的region
4.Zookeeper作用
1.通过选举，保证任何时候，集群中只有一个master，Master与RegionServers 启动时会向ZooKeeper注册
2.存贮所有Region的寻址入口
3.实时监控Region server的上线和下线信息。并实时通知给Master
4.存储HBase的schema和table元数据
5.默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper
6.Zookeeper的引入使得Master不再是单点故障

2.yarn资源调度流程
1.client发出请求到resourceManager
2.resourceManager启动Appication master为任务分配相关的资源，分配完成后返回信息到resourceManager
3.再由resourceManager将任务分发到不同的NodeManager。
4.NodeManager启动Container执行需要的MapReduce工作

3.kafka存储机制
1）kafka以topic来进行消息管理，每个topic包含多个partition，每个partition对应一个逻辑log，有多个segment组成。
2）每个segment中存储多条消息（见下图），消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避
免id到位置的额外映射。
3）每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。
4）发布者发到某个topic的消息会被均匀的分布到多个partition上（或根据用户指定的路由规则进行分布），broker收到
发布消息往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超
过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后
将不会再往该segment写数据，broker会创建新的segment。

4.zookeeper什么地方用到他

5.linux常用操作10个，（简单的就算了）（一些日志的查看，会用到的）

6.mapPartition和map执行流程上有什么区别
1）map的输入变换函数是应用于RDD中每个元素，而mapPartitions的输入函数是应用于每个分区。
假设一个rdd有10个元素，分成3个分区。如果使用map方法，map中的输入函数会被调用10次；而使用mapPartitions
方法的话，其输入函数会只会被调用3次，每个分区调用1次。
2）从输入函数（myfuncPerElement、myfuncPerPartition）层面来看，map是推模式，数据被推到myfuncPerElement
中；mapPartitons是拉模式，myfuncPerPartition通过迭代子从分区中拉数据
3）大数据集情况下的资源初始化开销和批处理处理，如果在myfuncPerPartition和myfuncPerElement中都要初始化一个
耗时的资源，然后使用，比如数据库连接。在上面的例子中，myfuncPerPartition只需初始化3个资源（3个分区每个1次），
而myfuncPerElement要初始化10次（10个元素每个1次），显然在大数据集情况下（数据集中元素个数远大于分区数），
mapPartitons的开销要小很多，也便于进行批处理操作。

7.foreach和foreachPartition区别
1）foreach是直接在每个partition中直接对iterator执行foreach操作,而传入的function只是在foreach内部使用,
2）foreachPartition是在每个partition中把iterator给传入的function,让function自己对iterator进行处理（可以避免内存溢出）

8.map和foreach有什么异同
相同点：
1）都是循环遍历数组中的每一项
2）forEach和map方法里每次执行匿名函数都支持3个参数，参数分别是item（当前每一项）、index（索引值）、arr（原数组）
3）匿名函数中的this都是指向window
4）只能遍历数组
区别：
1）map方法返回一个新的数组，数组中的元素为原始数组调用函数处理后的值。 
我的理解就是：原数组进行处理之后对应的一个新的数组。 
map()方法按照原始数组元素顺序依次处理元素。 
注意：map()方法不会对空数组进行检测。 
map()方法不会改变原始数组。
2）forEach()方法用于调用数组的每个元素，将元素传给回调函数。 
注意：forEach对于空数组是不会调用回调函数的。 
 
9.leader和follower是干嘛呢
（1）只有1个leader线程，可以有若干的follower线程；
（2）线程有3种状态：leading/processing/following；
（3）有一把锁，抢到的就是leading；
（4）事件来到时，leading线程会对其进行处理，从而转化为processing状态；
（5）处理完成后，尝试抢锁，抢到则又变为leading，否则变为followering；
（6）followering不干事，就是抢锁，力图成为leading；
10.kafka的组件

晚上：（电话面试）
网心科技：
1.kafka为什么要进行分区，怎么分区
2.Spark on yarn有分为两种模式yarn-cluster和yarn-client主要区别
3.简单介绍一下sparkRDD
4.HIVE分区和分桶
5.hive为什么不支持很多文件夹
6.小文件夹怎么操作（他说是在运行的时候，map端应该怎么设置之类）
7.小文件夹怎么合并
8.cores给30个只用了10个，该怎么解决
9.yarn的资源调度
10.发现数据处理比较慢，该怎么解决
11.数据清洗，同一批数据，形成7，8个报表，怎么分解任务
12.flume熟悉吗？
13.存入HBASE或者mysql的依据是什么
14.几种排序算法，时间复杂度

周三：
公司：岩心科技
1.上来一套笔试题：没拍照，因为面试官做我对面（临走把试卷给收走了）
Hbase Rowkey设计原则
kafka的exactly-once
hashmap与hashtable与？？（没记住）的区别
jvm相关的
其他记不住了
因为我说java不熟，就把前三个做了一下
2.yarn的资源调度原理
3.spark shuffle和MR shuffle区别
4.聊项目
5.最后和人力聊
6.要了25k，说两天后给回复

公司：
网心科技：
突然联系我，说昨天技术面过了，什么时候来当面聊聊，我说只能下周，这周包括晚上已经全部排满，
结果发现我就在这个公司附近，就面试完上一家就不行去了，从11：30开始面试，面试到12：20
主要聊一些项目
1.项目中遇到的难题
2.昨天电话面试的没回答出来的问题
然后聊着聊着都感觉比较好，中间我会主动查一些话，比如公司spark用到的多还是MR
由于人力去吃饭了，我们俩又聊到1：00，就聊公司的一些情况，和我在前公司的情况，
然后一些想法的交流，人力聊完就1：40左右了，当场暗示说会给offer

公司：
星聚网络：（今天比较幸运，三家公司在两公里以内）
小公司，上来问我java，我说我只有清洗才会用java，所以java很多原理性的不懂
然后他不懂大数据，就象征性的问了几个没深度的问题，然后我就把话接过来了（此人可能是java开发的，不太会聊天）
说了我做了哪些，项目流程，
然后他就给我说，我们公司有一个大数据离职了，给我说公司大数据项目流程，问我愿不愿意接受挑战，
我就问了一下，公司每条数据多大，本来我想提示一下，结果他抢答说几百kb（我就。。），我问公司数据量多大，他说
几个G，然后我说，我曾经做过实验，就是几个G的数据可以用txt编辑器打开（这个一定要注意方式）
然后他就说如果你愿意接受挑战，我就叫我们领导过来，我就说了一下我职业规划，就婉拒了

然后结束之后，网心科技人力打电话过来，聊薪资，聊是否愿意来公司，然后六点的时候又给了一个电话，就把待遇说
了一下，问能否接受，然后就给邮件offer了