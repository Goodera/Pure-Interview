1 spark中项目离线可以用hive ，而且前面有etl清洗 为什么选用spark 进行分析，技你们术选型根据什么定的。
2 你们这个项目中用什么进行调度 ，怎么保证数据不出错
3 离线任务是定时跑吗？时间力度怎样？如果数据没有及时过来 怎么跑？
4 如果你前面的数据出现问题，然后数据为空，你需要跑历史数据，遇到过吗 ？怎么解决
5一些脏数据怎么处理 ，怎么脏数据过滤、出去，用工具还是？
6 实时和离线数据都放入MySQL中 ，能行？
7 你们数据怎么跑 ，你测试数据和生产数据差很多，怎么保证你的代码不出问题
8 spark 项目中 是行为数据多还是业务数据多，在服务器集群上拉去的数据大概多少张
9 spark 项目 你拉去的这张表是张大表是吗? 涉及别的表吗？
10 前端展示那你们怎么展示 ，用工具还是?
11你参数怎么设置的，你提交jar包时，不提前和测试的商量分配多少资源吗（spark）
12 hive 项目，分几个主题 （spark项目中这个问题也有问到过）
13 sparkstreaming 拉去实时数据怎么保证数据不丢失 ，你们代码中是怎么设置的，api方面的问题
14 怎么将数据存入到MySQL库中
15  看了技术框架后，问你没想从技术选型上进行优化过吗（spark）？
16 项目中涉及到的字段，两个项目都有问道

